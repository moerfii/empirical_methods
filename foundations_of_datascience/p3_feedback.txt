# Repository M52-FDS20 Practical 3

## Task 1. ANN: 11.5/15

Correct submission for Task 1.

3.5 points deducted -- (Task 1) Quite a short report, but we do not have any general concerns. An interesting point to discuss: "The RandomizedSearchCV did not provide any useful information in this case, as all the accuracies were very close to each other." - we would have wanted to see the randomized cross validation implemented and not just mentioned in the report, so that we can trust they actually tried it.


## Task 2. Transfer Learning: 20.0/25

Correct submission for Task 2.

5 points deducted -- (Task 2) Not the most coherent report, with a few typos, showing it might be rushed. It does explain what they have done, but it is mostly a list of what changes have been made and how they impacted the accuracy, with not a lot of justification. They have actually implemented the model with upscaling, which performed better (~90% accuracy), but took ~20 hours to train for 3 epochs, so they did not pursue this avenue any further (most likely understanding that 80%+ accuracy is all that was required). AveragePooling computes linear combinations, so it can in theory be learned by a dense layer (possibly with some flattening), as a response to: "We then also added an MaxPooling before our dense layers to recognise the most significant features, but we then realised that in our case, AveragePooling perfomed better, so we chose AveragePooling".



The marks are based on the accuracy of the models and the quality of the reports. 

Overall: 31.5/40

